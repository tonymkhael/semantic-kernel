{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "3c93ac5b",
            "metadata": {},
            "source": [
                "# Running Prompt Functions Inline\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "40201641",
            "metadata": {},
            "source": [
                "The [previous notebook](./02-running-prompts-from-file.ipynb)\n",
                "showed how to define a semantic function using a prompt template stored on a file.\n",
                "\n",
                "In this notebook, we'll show how to use the Semantic Kernel to define functions inline with your python code. This can be useful in a few scenarios:\n",
                "\n",
                "- Dynamically generating the prompt using complex rules at runtime\n",
                "- Writing prompts by editing Python code instead of TXT files.\n",
                "- Easily creating demos, like this document\n",
                "\n",
                "Prompt templates are defined using the SK template language, which allows to reference variables and functions. Read [this doc](https://aka.ms/sk/howto/configurefunction) to learn more about the design decisions for prompt templating.\n",
                "\n",
                "For now we'll use only the `{{$input}}` variable, and see more complex templates later.\n",
                "\n",
                "Almost all semantic function prompts have a reference to `{{$input}}`, which is the default way\n",
                "a user can import content from the context variables.\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "d90b0c13",
            "metadata": {},
            "source": [
                "Prepare a semantic kernel instance first, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1da651d4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: semantic-kernel==0.9.6b1 in c:\\python312\\lib\\site-packages (0.9.6b1)\n",
                        "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.9.5)\n",
                        "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.7.1)\n",
                        "Requirement already satisfied: grpcio>=1.50.0 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.62.2)\n",
                        "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.1.3)\n",
                        "Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.4.0)\n",
                        "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\azureuser\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.6b1) (1.6.0)\n",
                        "Requirement already satisfied: numpy>=1.26 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.26.4)\n",
                        "Requirement already satisfied: openai>=1.0 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.23.6)\n",
                        "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.19.1)\n",
                        "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (23.6.21.0)\n",
                        "Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.9.13)\n",
                        "Requirement already satisfied: pydantic<3,>=2 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2.7.1)\n",
                        "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.0.1)\n",
                        "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2023.12.25)\n",
                        "Requirement already satisfied: scipy>=1.12.0 in c:\\python312\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.13.0)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.3.1)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (23.2.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.4.1)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (6.0.5)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.9.4)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel==0.9.6b1) (2.1.5)\n",
                        "Requirement already satisfied: pymongo<5,>=4.5 in c:\\python312\\lib\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (4.7.0)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.3.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (0.27.0)\n",
                        "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.66.2)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.11.0)\n",
                        "Requirement already satisfied: isodate in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.1)\n",
                        "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (4.21.1)\n",
                        "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.3.2)\n",
                        "Requirement already satisfied: more-itertools in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (10.2.0)\n",
                        "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.2)\n",
                        "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.7.1)\n",
                        "Requirement already satisfied: parse in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.20.1)\n",
                        "Requirement already satisfied: werkzeug in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (3.0.2)\n",
                        "Requirement already satisfied: chardet>=3.0 in c:\\python312\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (5.2.0)\n",
                        "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\python312\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.18.6)\n",
                        "Requirement already satisfied: requests>=2.25 in c:\\python312\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.31.0)\n",
                        "Requirement already satisfied: six~=1.15 in c:\\users\\azureuser\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (1.16.0)\n",
                        "Requirement already satisfied: packaging>=21.3 in c:\\users\\azureuser\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (24.0)\n",
                        "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\python312\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic-kernel==0.9.6b1) (0.5.1)\n",
                        "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (0.6.0)\n",
                        "Requirement already satisfied: pydantic-core==2.18.2 in c:\\python312\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (2.18.2)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.6b1) (3.7)\n",
                        "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (2024.2.2)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (1.0.5)\n",
                        "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (0.14.0)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (2023.12.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.31.1)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.18.0)\n",
                        "Requirement already satisfied: PyYAML>=5.1 in c:\\python312\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (6.0.1)\n",
                        "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\python312\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.4.3)\n",
                        "Requirement already satisfied: rfc3339-validator in c:\\python312\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.1.4)\n",
                        "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\python312\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.10.0)\n",
                        "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\python312\\lib\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (2.6.1)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (3.3.2)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.2.1)\n",
                        "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\python312\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.2.8)\n",
                        "Requirement already satisfied: colorama in c:\\users\\azureuser\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==0.9.6b1) (0.4.6)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "source": [
                "!python -m pip install semantic-kernel==0.9.6b1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "68b770df",
            "metadata": {},
            "outputs": [],
            "source": [
                "from services import Service\n",
                "\n",
                "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
                "selectedService = Service.AzureOpenAI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "3712b7c3",
            "metadata": {},
            "outputs": [],
            "source": [
                "import semantic_kernel as sk\n",
                "\n",
                "kernel = sk.Kernel()\n",
                "\n",
                "service_id = None\n",
                "if selectedService == Service.OpenAI:\n",
                "    from semantic_kernel.connectors.ai.open_ai import OpenAITextCompletion\n",
                "\n",
                "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
                "    service_id = \"oai_text_completion\"\n",
                "    kernel.add_service(\n",
                "        OpenAITextCompletion(\n",
                "            service_id=service_id, ai_model_id=\"gpt-3.5-turbo-instruct\", api_key=api_key, org_id=org_id\n",
                "        ),\n",
                "    )\n",
                "elif selectedService == Service.AzureOpenAI:\n",
                "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
                "    from semantic_kernel.utils.settings import azure_openai_settings_from_dot_env\n",
                "\n",
                "    deployment, api_key, endpoint = azure_openai_settings_from_dot_env()\n",
                "    service_id = \"aoai_text_completion\"\n",
                "    kernel.add_service(\n",
                "        AzureTextCompletion(service_id=service_id, deployment_name=deployment, endpoint=endpoint, api_key=api_key),\n",
                "    )"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "589733c5",
            "metadata": {},
            "source": [
                "Let's use a prompt to create a semantic function used to summarize content, allowing for some creativity and a sufficient number of tokens.\n",
                "\n",
                "The function will take in input the text to summarize.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "314557fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "input_text = \"\"\"\n",
                "Demo (ancient Greek poet)\n",
                "From Wikipedia, the free encyclopedia\n",
                "Demo or Damo (Greek: Δεμώ, Δαμώ; fl. c. AD 200) was a Greek woman of the Roman period, known for a single epigram, engraved upon the Colossus of Memnon, which bears her name. She speaks of herself therein as a lyric poetess dedicated to the Muses, but nothing is known of her life.[1]\n",
                "Identity\n",
                "Demo was evidently Greek, as her name, a traditional epithet of Demeter, signifies. The name was relatively common in the Hellenistic world, in Egypt and elsewhere, and she cannot be further identified. The date of her visit to the Colossus of Memnon cannot be established with certainty, but internal evidence on the left leg suggests her poem was inscribed there at some point in or after AD 196.[2]\n",
                "Epigram\n",
                "There are a number of graffiti inscriptions on the Colossus of Memnon. Following three epigrams by Julia Balbilla, a fourth epigram, in elegiac couplets, entitled and presumably authored by \"Demo\" or \"Damo\" (the Greek inscription is difficult to read), is a dedication to the Muses.[2] The poem is traditionally published with the works of Balbilla, though the internal evidence suggests a different author.[1]\n",
                "In the poem, Demo explains that Memnon has shown her special respect. In return, Demo offers the gift for poetry, as a gift to the hero. At the end of this epigram, she addresses Memnon, highlighting his divine status by recalling his strength and holiness.[2]\n",
                "Demo, like Julia Balbilla, writes in the artificial and poetic Aeolic dialect. The language indicates she was knowledgeable in Homeric poetry—'bearing a pleasant gift', for example, alludes to the use of that phrase throughout the Iliad and Odyssey.[a][2] \n",
                "\"\"\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "bf0f2330",
            "metadata": {},
            "source": [
                "...and run the summary function:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b0e3b0c",
            "metadata": {},
            "outputs": [],
            "source": [
                "summary = await kernel.invoke(summarize, sk.KernelArguments(input=input_text))\n",
                "\n",
                "print(summary)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1c2c1262",
            "metadata": {},
            "source": [
                "# Using ChatCompletion for Semantic Plugins\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "29b59b28",
            "metadata": {},
            "source": [
                "You can also use chat completion models (like `gpt-35-turbo` and `gpt4`) for creating plugins. Normally you would have to tweak the API to accommodate for a system and user role, but SK abstracts that away for you by using `kernel.add_service` and `AzureChatCompletion` or `OpenAIChatCompletion`\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "4777f447",
            "metadata": {},
            "source": [
                "Here's one more example of how to write an inline Semantic Function that gives a TLDR for a piece of text using a ChatCompletion model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c5886aeb",
            "metadata": {},
            "outputs": [],
            "source": [
                "kernel = sk.Kernel()\n",
                "\n",
                "service_id = None\n",
                "if selectedService == Service.OpenAI:\n",
                "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
                "\n",
                "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
                "    service_id = \"oai_chat_gpt\"\n",
                "    kernel.add_service(\n",
                "        OpenAIChatCompletion(service_id=service_id, ai_model_id=\"gpt-3.5-turbo-1106\", api_key=api_key, org_id=org_id),\n",
                "    )\n",
                "elif selectedService == Service.AzureOpenAI:\n",
                "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
                "\n",
                "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
                "    service_id = \"aoai_chat_completion\"\n",
                "    kernel.add_service(\n",
                "        AzureChatCompletion(service_id=service_id, deployment_name=deployment, endpoint=endpoint, api_key=api_key),\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "ea8128c8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Output: \n",
                        "OP: Robots love us, protect us. \n",
                        "\n",
                        "YumilAttack:  I-Robot without Will Smith. \n",
                        "\n",
                        "OP: I wish I was Will Smith. \n",
                        "\n",
                        "YumilAttack:  You're right. That would be great. \n",
                        "\n",
                        "OP: I think I'm done with my AMA. \n",
                        "\n",
                        "YumilAttack:  Thanks for stopping by. \n",
                        "\n",
                        "OP: Thanks for coming out. \n",
                        "\n",
                        "YumilAttack:  I'm just waiting for the after party. \n",
                        "\n",
                        "OP: Well, we're out of cookies and punch but I think we can all just sit around and talk about how much we love Will Smith. \n",
                        "\n",
                        "YumilAttack:  Honestly, I would rather talk about you. \n",
                        "\n",
                        "OP: I keep hearing that from people. \n",
                        "\n",
                        "YumilAttack:  I don't know what it is but you have that certain something. I am going to go with your eyes. \n",
                        "\n",
                        "OP: I thought it was my ability to rock a turtleneck. \n",
                        "\n",
                        "YumilAttack:  That too. \n",
                        "\n",
                        "OP: I'm glad we could come to a consensus. \n",
                        "\n",
                        "YumilAttack:  Lets celebrate with some cookies and punch. \n",
                        "\n",
                        "OP: I'm sorry, we're all out. \n",
                        "\n",
                        "YumilAttack:  That's ok. I am sure that Will Smith's house has cookies and punch. \n",
                        "\n",
                        "OP: It's probably a requirement that he have cookies and punch. \n",
                        "\n",
                        "YumilAttack:  I bet he is eating cookies and drinking punch right now. \n",
                        "\n",
                        "OP: And he's probably wearing a turtleneck. \n",
                        "\n",
                        "YumilAttack:  You are right. \n",
                        "\n",
                        "OP: I'm always right when it comes to Will Smith. \n",
                        "\n",
                        "YumilAttack:  I think you could be right about a lot of things. \n",
                        "\n",
                        "OP: That's a lot of pressure, but I think I can handle it. \n",
                        "\n",
                        "YumilAttack:  I have faith in you. Will Smith would be proud. \n",
                        "\n",
                        "OP: I hope so. I'd hate to disappoint him. \n",
                        "\n",
                        "YumilAttack:  I am sure you won't. \n",
                        "\n",
                        "OP: I'll try my best. \n",
                        "\n",
                        "YumilAttack:  I am sure that will be good enough. \n",
                        "\n",
                        "OP: If it's not, I'll just put on a turtleneck. \n",
                        "\n",
                        "YumilAttack:  That would be perfect. \n",
                        "\n",
                        "OP: It really is a versatile garment. \n",
                        "\n",
                        "YumilAttack:  It really is. \n",
                        "\n",
                        "OP: I'm glad we could come to an agreement about that. \n",
                        "\n",
                        "YumilAttack:  It's always good to agree. \n",
                        "\n",
                        "OP: Agreed. \n",
                        "\n",
                        "YumilAttack:  Well good luck with everything. \n",
                        "\n",
                        "OP: Thank you. Good luck to you, too. \n",
                        "\n",
                        "YumilAttack:  Thanks. \n",
                        "\n",
                        "OP: Bye. \n",
                        "\n",
                        "YumilAttack:  Bye. \n",
                        "\n",
                        "OP: Do you want to go to Will Smith's house? \n",
                        "\n",
                        "YumilAttack:  I thought you would never ask! \n",
                        "\n",
                        "OP: Okay, let's go. \n",
                        "\n",
                        "YumilAttack:  Wait how are we getting there? \n",
                        "\n",
                        "OP: We're going to have to walk. \n",
                        "\n",
                        "YumilAttack:  Ok, I will pack a lunch. \n",
                        "\n",
                        "OP: Don't forget the cookies and punch. \n",
                        "\n",
                        "YumilAttack:  I have my priorities straight. \n",
                        "\n",
                        "OP: That's why I like you. \n",
                        "\n",
                        "YumilAttack:  I don't know if that is good or bad. \n",
                        "\n",
                        "OP: It's definitely a good thing. \n",
                        "\n",
                        "YumilAttack:  Ok good. \n",
                        "\n",
                        "OP: Now let's hurry up and get to Will's house. \n",
                        "\n",
                        "YumilAttack:  I have never walked this far. How long do you think it will take? \n",
                        "\n",
                        "OP: Well, we're just going to walk until we see a giant house with the words \"Will Smith's House\" on it. \n",
                        "\n",
                        "YumilAttack:  That seems like a solid plan.\n",
                        "\n",
                        "OP: I'm full of those. \n",
                        "\n",
                        "YumilAttack:  It's one of the reasons why I like you. \n",
                        "\n",
                        "OP: I'm glad. I like you, too. \n",
                        "\n",
                        "YumilAttack:  I am not sure why, but I am happy about it. \n",
                        "\n",
                        "OP: You're happy because I'm charming and witty. \n",
                        "\n",
                        "YumilAttack:  I think that's it. \n",
                        "\n",
                        "OP: I know it's it. \n",
                        "\n",
                        "YumilAttack:  Ok, you win. \n",
                        "\n",
                        "OP: I knew it. \n",
                        "\n",
                        "YumilAttack:  You really are good at this. \n",
                        "\n",
                        "OP: It's a gift. \n",
                        "\n",
                        "YumilAttack:  You should use it more often. \n",
                        "\n",
                        "OP: I try to. \n",
                        "\n",
                        "YumilAttack:  I can tell. \n",
                        "\n",
                        "OP: What else can you tell about me? \n",
                        "\n",
                        "YumilAttack:  That you are unique. \n",
                        "\n",
                        "OP: What makes me unique? \n",
                        "\n",
                        "YumilAttack:  You have a style all your own. \n",
                        "\n",
                        "OP: Do you think Will Smith would like my style? \n",
                        "\n",
                        "YumilAttack:  I think he would be impressed. \n",
                        "\n",
                        "OP: Thank you. \n",
                        "\n",
                        "YumilAttack:  You're welcome. \n",
                        "\n",
                        "OP: I hope he invites us in for cookies and punch. \n",
                        "\n",
                        "YumilAttack:  I am sure he will. \n",
                        "\n",
                        "OP: I really want a cookie. \n",
                        "\n",
                        "YumilAttack:  Me too. \n",
                        "\n",
                        "OP: Maybe we should pick up a few cookies for him. \n",
                        "\n",
                        "YumilAttack:  That's a great idea. \n",
                        "\n",
                        "OP: I know. I'm full of them. \n",
                        "\n",
                        "YumilAttack:  I can't wait to see his house. \n",
                        "\n",
                        "OP: I know. It's going to be so cool. \n",
                        "\n",
                        "YumilAttack:  I hope he has a tennis court. \n",
                        "\n",
                        "OP: I hope he has a pool. \n",
                        "\n",
                        "YumilAttack:  I hope he has a pool table. \n",
                        "\n",
                        "OP: I hope he has a bowling alley. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Ferris wheel. \n",
                        "\n",
                        "OP: I hope he has a rollercoaster. \n",
                        "\n",
                        "YumilAttack:  I hope he has a waterslide. \n",
                        "\n",
                        "OP: I hope he has a zip line. \n",
                        "\n",
                        "YumilAttack:  I hope he has a go cart track. \n",
                        "\n",
                        "OP: I hope he has a batting cage. \n",
                        "\n",
                        "YumilAttack:  I hope he has a basketball court. \n",
                        "\n",
                        "OP: I hope he has a football field. \n",
                        "\n",
                        "YumilAttack:  I hope he has a zoo. \n",
                        "\n",
                        "OP: I hope he has a movie theater. \n",
                        "\n",
                        "YumilAttack:  I hope he has a golf course. \n",
                        "\n",
                        "OP: I hope he has a private jet. \n",
                        "\n",
                        "YumilAttack:  I hope he has a space shuttle. \n",
                        "\n",
                        "OP: I hope he has a time machine. \n",
                        "\n",
                        "YumilAttack:  I hope he has a hover board. \n",
                        "\n",
                        "OP: I hope he has a portal gun. \n",
                        "\n",
                        "YumilAttack:  I hope he has a teleportation device. \n",
                        "\n",
                        "OP: I hope he has a shrink ray. \n",
                        "\n",
                        "YumilAttack:  I hope he has an invisibility cloak. \n",
                        "\n",
                        "OP: I hope he has a lightsaber. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Tardis. \n",
                        "\n",
                        "OP: I hope he has a dragon. \n",
                        "\n",
                        "YumilAttack:  I hope he has a unicorn. \n",
                        "\n",
                        "OP: I hope he has a pegasus. \n",
                        "\n",
                        "YumilAttack:  I hope he has a griffin. \n",
                        "\n",
                        "OP: I hope he has a basilisk. \n",
                        "\n",
                        "YumilAttack:  I hope he has a gryphon. \n",
                        "\n",
                        "OP: I hope he has a chimera. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Minotaur. \n",
                        "\n",
                        "OP: I hope he has a mermaid. \n",
                        "\n",
                        "YumilAttack:  I hope he has a centaur. \n",
                        "\n",
                        "OP: I hope he has a giant. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Cyclops. \n",
                        "\n",
                        "OP: I hope he has a kraken. \n",
                        "\n",
                        "YumilAttack:  I hope he has a hydra. \n",
                        "\n",
                        "OP: I hope he has a sasquatch. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Loch Ness Monster. \n",
                        "\n",
                        "OP: I hope he has a phoenix. \n",
                        "\n",
                        "YumilAttack:  I hope he has a Yeti. \n",
                        "\n",
                        "OP: I hope he has an ogre. \n",
                        "\n",
                        "YumilAttack:  I hope he has a leprechaun. \n",
                        "\n",
                        "OP: I hope he has a gremlin. \n",
                        "\n",
                        "YumilAttack:  I hope he has a gargoyle. \n",
                        "\n",
                        "OP: I hope he has a troll. \n",
                        "\n",
                        "YumilAttack:  I hope he has a genie. \n",
                        "\n",
                        "OP: I hope he has a vampire. \n",
                        "\n",
                        "YumilAttack:  I hope he has a wer\n"
                    ]
                }
            ],
            "source": [
                "prompt = \"\"\"\n",
                "{{$input}}\n",
                "\n",
                "Give me the TLDR in 5 words or less.\n",
                "\"\"\"\n",
                "\n",
                "text = \"\"\"\n",
                "    1) A robot may not injure a human being or, through inaction,\n",
                "    allow a human being to come to harm.\n",
                "\n",
                "    2) A robot must obey orders given it by human beings except where\n",
                "    such orders would conflict with the First Law.\n",
                "\n",
                "    3) A robot must protect its own existence as long as such protection\n",
                "    does not conflict with the First or Second Law.\n",
                "\"\"\"\n",
                "\n",
                "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.open_ai_prompt_execution_settings import (\n",
                "    OpenAIChatPromptExecutionSettings,\n",
                ")\n",
                "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
                "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
                "from semantic_kernel.functions import KernelArguments\n",
                "\n",
                "if selectedService == Service.OpenAI:\n",
                "    execution_settings = OpenAIChatPromptExecutionSettings(\n",
                "        service_id=service_id,\n",
                "        ai_model_id=\"gpt-3.5-turbo-1106\",\n",
                "        max_tokens=2000,\n",
                "        temperature=0.7,\n",
                "    )\n",
                "elif selectedService == Service.AzureOpenAI:\n",
                "    execution_settings = OpenAIChatPromptExecutionSettings(\n",
                "        service_id=service_id,\n",
                "        ai_model_id=deployment,\n",
                "        max_tokens=2000,\n",
                "        temperature=0.7,\n",
                "    )\n",
                "\n",
                "prompt_template_config = PromptTemplateConfig(\n",
                "    template=prompt,\n",
                "    name=\"tldr\",\n",
                "    template_format=\"semantic-kernel\",\n",
                "    input_variables=[\n",
                "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
                "    ],\n",
                "    execution_settings=execution_settings,\n",
                ")\n",
                "\n",
                "tldr_function = kernel.add_function(\n",
                "    function_name=\"tldrFunction\",\n",
                "    plugin_name=\"tldrPlugin\",\n",
                "    prompt_template_config=prompt_template_config,\n",
                ")\n",
                "\n",
                "summary = await kernel.invoke(tldr_function, KernelArguments(input=text))\n",
                "\n",
                "print(f\"Output: {summary}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
